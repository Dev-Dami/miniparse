# Core

This document explains the core components of the Miniparse library: `Tokenizer.ts`, `index.ts`, and `pipeline.ts`.

## Tokenizer.ts

The `Tokenizer.ts` file contains the `Tokenizer` class, which is responsible for breaking down a string of text into a sequence of tokens.

### `TokenType`

This type defines the different categories of tokens that can be identified:

- `word`: A sequence of letters.
- `number`: A sequence of digits.
- `punct`: Punctuation characters.
- `symbol`: Symbolic characters.
- `whitespace`: Spaces, tabs, and newlines.
- `unknown`: Any character that doesn't fit into the other categories.

### `Token`

This interface defines the structure of a token object:

- `value`: The string value of the token.
- `type`: The `TokenType` of the token.
- `start`: The starting index of the token in the original text.
- `end`: The ending index of the token in the original text.

### `TokenizerOptions`

This interface defines the options that can be passed to the `Tokenizer` constructor:

- `lowercase`: If `true`, all "word" tokens will be converted to lowercase. Defaults to `true`.
- `mergeSymbols`: If `true`, consecutive "symbol" tokens will be merged into a single token. Defaults to `false`.

### `Tokenizer` class

The `Tokenizer` class has the following methods:

- `constructor(options?: TokenizerOptions)`: Creates a new `Tokenizer` instance with the given options.
- `tokenize(text: string): Token[]`: Tokenizes the given text and returns an array of `Token` objects.

## index.ts

The `index.ts` file defines the core interfaces used by the pipeline.

### `Entity`

This interface defines the structure of an entity object, which represents a piece of information extracted from the text:

- `type`: The type of the entity (e.g., "person", "location").
- `value`: The string value of the entity.
- `start`: The starting index of the entity in the original text.
- `end`: The ending index of the entity in the original text.

### `IntentResult`

This interface defines the structure of the object that is passed through the pipeline:

- `text`: The original input text.
- `tokens`: An array of `Token` objects generated by the `Tokenizer`.
- `entities`: An array of `Entity` objects extracted from the text.

## pipeline.ts

The `pipeline.ts` file contains the `Pipeline` class, which is responsible for processing text through a series of components.

### `PipelineComponent`

This type defines a function that can be used as a component in the pipeline. It takes an `IntentResult` object as input and returns an `IntentResult` object.

### `Pipeline` class

The `Pipeline` class has the following methods:

- `constructor()`: Creates a new `Pipeline` instance.
- `use(component: PipelineComponent): this`: Adds a component to the pipeline.
- `process(text: string): Promise<IntentResult>`: Processes the given text through the pipeline and returns an `IntentResult` object.

### Example Usage

Here is an example of how to create a pipeline and use it to process text:

```typescript
import { Pipeline, PipelineComponent } from "./core/pipeline";
import { IntentResult } from "./core";

// A simple component that identifies numbers as entities.
const numberEntityExtractor: PipelineComponent = (input: IntentResult) => {
  for (const token of input.tokens) {
    if (token.type === "number") {
      input.entities.push({
        type: "number",
        value: token.value,
        start: token.start,
        end: token.end,
      });
    }
  }
  return input;
};

const pipeline = new Pipeline();
pipeline.use(numberEntityExtractor);

pipeline.process("I have 2 apples and 3 oranges.").then((result) => {
  console.log(result.entities);
  // Output:
  // [
  //   { type: 'number', value: '2', start: 7, end: 8 },
  //   { type: 'number', value: '3', start: 20, end: 21 }
  // ]
});
```
